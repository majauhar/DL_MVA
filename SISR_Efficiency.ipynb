{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majauhar/DL_MVA/blob/main/SISR_Efficiency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5KLUtn6E2H0u"
      },
      "outputs": [],
      "source": [
        "# For local environments:\n",
        "# Local installation on Colab results into non-availability of submodules\n",
        "# !git clone https://github.com/majauhar/fvcore.git\n",
        "# !pip install -e fvcore\n",
        "# !pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "toLHXTix6PBp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nFor Colab environments:\\nWouldn't work for OMNI-SR because of a bug in the original package\\nWhich I have fixed in my fork.\\n\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "For Colab environments:\n",
        "Wouldn't work for OMNI-SR because of a bug in the original package\n",
        "Which I have fixed in my fork.\n",
        "\"\"\"\n",
        "# %pip install fvcore -q\n",
        "# %pip install einops -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH7JWr5_h4lJ",
        "outputId": "485c5538-8de0-4237-b2cb-7afd16042175"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/majauhar/DL_MVA.git\n",
        "# cd DL_MVA/\n",
        "# !git clone https://github.com/hellloxiaotian/LESRCNN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "from fvcore.nn import flop_count_str\n",
        "from fvcore.nn import flop_count_table\n",
        "from time import perf_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS1LfMXrlodL",
        "outputId": "87586739-d7c7-4228-db30-bb4ba2fb1d7c"
      },
      "outputs": [],
      "source": [
        "# Local imports\n",
        "from utils.efficiency_results import get_model_flops, get_model_activation\n",
        "from lesrcnn.model import Net\n",
        "from omni.model import OmniSR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_inference(model, input):\n",
        "    \"\"\"\n",
        "        Little function for calculating inference time\n",
        "        Averages over 100 inferences\n",
        "    \"\"\"\n",
        "    start_time = perf_counter()\n",
        "    _ = model(input)\n",
        "    end_time = perf_counter()\n",
        "    delta = end_time - start_time\n",
        "    \n",
        "    return delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SHYZ0yxsn5g1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n",
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n",
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n",
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n",
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jauhar/miniconda3/envs/ml/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "# model = Net() # LESRCNN \n",
        "model = OmniSR() # Omni-SR network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "deltas = []\n",
        "for _ in range(100):\n",
        "    input = torch.randn(1, 3, 256, 256)\n",
        "    deltas.append(forward_inference(model, input))\n",
        "\n",
        "average_time = np.array(deltas).mean()\n",
        "print(\"inference time: {:.2f} ms\".format(average_time * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ-DBLqnn_Xm",
        "outputId": "79146607-ec29-46af-f24f-ce090cfac0c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    #Activations : 173.7359 [M]\n",
            "         #Conv2d : 26\n",
            "           FLOPs : 80.1813 [G]\n",
            "         #Params : 0.6263 [M]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "To find the number of activations.\n",
        "Model summary tools based on NTIRE challenge on efficient super-resolution: https://cvlai.net/ntire/2023/\n",
        "\"\"\"\n",
        "input_dim = (3, 256, 256)\n",
        "activations, num_conv = get_model_activation(model, input_dim)\n",
        "activations = activations / 10 ** 6\n",
        "print(\"{:>16s} : {:<.4f} [M]\".format(\"#Activations\", activations))\n",
        "print(\"{:>16s} : {:<d}\".format(\"#Conv2d\", num_conv))\n",
        "\n",
        "\n",
        "flops = get_model_flops(model, input_dim, False)\n",
        "flops = flops / 10 ** 9\n",
        "print(\"{:>16s} : {:<.4f} [G]\".format(\"FLOPs\", flops))\n",
        "\n",
        "num_parameters = sum(map(lambda x: x.numel(), model.parameters()))\n",
        "num_parameters = num_parameters / 10 ** 6\n",
        "print(\"{:>16s} : {:<.4f} [M]\".format(\"#Params\", num_parameters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugPCdvaTs8HQ",
        "outputId": "490650d5-e4cd-46b3-d2a5-8a0c5d642eaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsupported operator aten::add encountered 9 time(s)\n",
            "Unsupported operator aten::pixel_shuffle encountered 2 time(s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FLOPs: {.3f} [G] 80.026075136\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Alternative tool for calculating FLOPs: Fvcore by Facebook research\n",
        "https://github.com/facebookresearch/fvcore\n",
        "\"\"\"\n",
        "\n",
        "input = torch.randn(1, 3, 256, 256)\n",
        "flops = FlopCountAnalysis(model, input)\n",
        "print(\"FLOPs: {:.2f} [G]\".format(flops.total() / 1e9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| module                      | #parameters or shape   | #flops   |\n",
            "|:----------------------------|:-----------------------|:---------|\n",
            "| model                       | 0.626M                 | 80.026G  |\n",
            "|  sub_mean.shifter           |  12                    |  0.59M   |\n",
            "|   sub_mean.shifter.weight   |   (3, 3, 1, 1)         |          |\n",
            "|   sub_mean.shifter.bias     |   (3,)                 |          |\n",
            "|  add_mean.shifter           |  12                    |  2.359M  |\n",
            "|   add_mean.shifter.weight   |   (3, 3, 1, 1)         |          |\n",
            "|   add_mean.shifter.bias     |   (3,)                 |          |\n",
            "|  conv1.0                    |  1.728K                |  0.113G  |\n",
            "|   conv1.0.weight            |   (64, 3, 3, 3)        |          |\n",
            "|  conv2.0                    |  36.864K               |  2.416G  |\n",
            "|   conv2.0.weight            |   (64, 64, 3, 3)       |          |\n",
            "|  conv3.0                    |  4.096K                |  0.268G  |\n",
            "|   conv3.0.weight            |   (64, 64, 1, 1)       |          |\n",
            "|  conv4.0                    |  36.864K               |  2.416G  |\n",
            "|   conv4.0.weight            |   (64, 64, 3, 3)       |          |\n",
            "|  conv5.0                    |  4.096K                |  0.268G  |\n",
            "|   conv5.0.weight            |   (64, 64, 1, 1)       |          |\n",
            "|  conv6.0                    |  36.864K               |  2.416G  |\n",
            "|   conv6.0.weight            |   (64, 64, 3, 3)       |          |\n",
            "|  conv7.0                    |  4.096K                |  0.268G  |\n",
            "|   conv7.0.weight            |   (64, 64, 1, 1)       |          |\n",
            "|  conv8.0                    |  36.864K               |  2.416G  |\n",
            "|   conv8.0.weight            |   (64, 64, 3, 3)       |          |\n",
            "|  conv9.0                    |  4.096K                |  0.268G  |\n",
            "|   conv9.0.weight            |   (64, 64, 1, 1)       |          |\n",
            "|  conv10.0                   |  36.864K               |  2.416G  |\n",
            "|   conv10.0.weight           |   (64, 64, 3, 3)       |          |\n",
            "|  conv11.0                   |  4.096K                |  0.268G  |\n",
            "|   conv11.0.weight           |   (64, 64, 1, 1)       |          |\n",
            "|  conv12.0                   |  36.864K               |  2.416G  |\n",
            "|   conv12.0.weight           |   (64, 64, 3, 3)       |          |\n",
            "|  conv13.0                   |  4.096K                |  0.268G  |\n",
            "|   conv13.0.weight           |   (64, 64, 1, 1)       |          |\n",
            "|  conv14.0                   |  36.864K               |  2.416G  |\n",
            "|   conv14.0.weight           |   (64, 64, 3, 3)       |          |\n",
            "|  conv15.0                   |  4.096K                |  0.268G  |\n",
            "|   conv15.0.weight           |   (64, 64, 1, 1)       |          |\n",
            "|  conv16.0                   |  36.864K               |  2.416G  |\n",
            "|   conv16.0.weight           |   (64, 64, 3, 3)       |          |\n",
            "|  conv17.0                   |  4.096K                |  0.268G  |\n",
            "|   conv17.0.weight           |   (64, 64, 1, 1)       |          |\n",
            "|  conv17_1.0                 |  36.864K               |  9.664G  |\n",
            "|   conv17_1.0.weight         |   (64, 64, 3, 3)       |          |\n",
            "|  conv17_2.0                 |  36.864K               |  9.664G  |\n",
            "|   conv17_2.0.weight         |   (64, 64, 3, 3)       |          |\n",
            "|  conv17_3.0                 |  36.864K               |  9.664G  |\n",
            "|   conv17_3.0.weight         |   (64, 64, 3, 3)       |          |\n",
            "|  conv17_4.0                 |  36.864K               |  9.664G  |\n",
            "|   conv17_4.0.weight         |   (64, 64, 3, 3)       |          |\n",
            "|  conv18.0                   |  1.728K                |  0.453G  |\n",
            "|   conv18.0.weight           |   (3, 64, 3, 3)        |          |\n",
            "|  upsample.up.body.0         |  0.148M                |  19.327G |\n",
            "|   upsample.up.body.0.weight |   (256, 64, 3, 3)      |          |\n",
            "|   upsample.up.body.0.bias   |   (256,)               |          |\n"
          ]
        }
      ],
      "source": [
        "# Layer-wise statistics\n",
        "print(flop_count_table(flops))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  #params: 0.63M, #flops: 80.03G\n",
            "  (sub_mean): MeanShift(\n",
            "    #params: 12, #flops: 0.59M\n",
            "    (shifter): Conv2d(\n",
            "      3, 3, kernel_size=(1, 1), stride=(1, 1)\n",
            "      #params: 12, #flops: 0.59M\n",
            "    )\n",
            "  )\n",
            "  (add_mean): MeanShift(\n",
            "    #params: 12, #flops: 2.36M\n",
            "    (shifter): Conv2d(\n",
            "      3, 3, kernel_size=(1, 1), stride=(1, 1)\n",
            "      #params: 12, #flops: 2.36M\n",
            "    )\n",
            "  )\n",
            "  (conv1): Sequential(\n",
            "    #params: 1.73K, #flops: 0.11G\n",
            "    (0): Conv2d(\n",
            "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 1.73K, #flops: 0.11G\n",
            "    )\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv6): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv7): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv8): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv9): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv10): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv11): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv12): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv13): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv14): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv15): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv16): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv17): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv17_1): Sequential(\n",
            "    #params: 36.86K, #flops: 9.66G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 9.66G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv17_2): Sequential(\n",
            "    #params: 36.86K, #flops: 9.66G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 9.66G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv17_3): Sequential(\n",
            "    #params: 36.86K, #flops: 9.66G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 9.66G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv17_4): Sequential(\n",
            "    #params: 36.86K, #flops: 9.66G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 9.66G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv18): Sequential(\n",
            "    #params: 1.73K, #flops: 0.45G\n",
            "    (0): Conv2d(\n",
            "      64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 1.73K, #flops: 0.45G\n",
            "    )\n",
            "  )\n",
            "  (ReLU): ReLU(inplace=True)\n",
            "  (upsample): UpsampleBlock(\n",
            "    #params: 0.15M, #flops: 19.33G\n",
            "    (up): _UpsampleBlock(\n",
            "      #params: 0.15M, #flops: 19.33G\n",
            "      (body): Sequential(\n",
            "        #params: 0.15M, #flops: 19.33G\n",
            "        (0): Conv2d(\n",
            "          64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          #params: 0.15M, #flops: 19.33G\n",
            "        )\n",
            "        (1): PixelShuffle(upscale_factor=2)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(flop_count_str(flops))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPk7Oc5AYORc0ZQ0t8jnmhT",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
