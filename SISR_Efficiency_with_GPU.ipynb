{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majauhar/DL_MVA/blob/main/SISR_Efficiency_with_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KLUtn6E2H0u"
      },
      "outputs": [],
      "source": [
        "# For local environments:\n",
        "# Local installation on Colab results into non-availability of submodules\n",
        "# !git clone https://github.com/majauhar/fvcore.git\n",
        "# !pip install -e fvcore\n",
        "# !pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "toLHXTix6PBp",
        "outputId": "00badbdd-7851-49cd-e837-a7d7274a4b50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "  For Colab environments:\n",
        "  Wouldn't work for OMNI-SR because of a bug in the original package\n",
        "  Which I have fixed in my fork.\n",
        "\"\"\"\n",
        "# %pip install fvcore -q\n",
        "%pip install einops -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aH7JWr5_h4lJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47d7a25-6c5c-4c06-8e6e-272acafcbf04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DL_MVA'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 107 (delta 39), reused 77 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 58.76 KiB | 2.03 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "  Required to run in Colab\n",
        "\"\"\"\n",
        "!git clone https://github.com/majauhar/DL_MVA.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd DL_MVA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE-iidvEEluj",
        "outputId": "161d57e7-65f1-4c03-fc92-863eb4000ddd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DL_MVA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w26WfIa7_pLU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import einops\n",
        "from time import perf_counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Unsafe for Colab (for Omni-SR, works fine with LESRCNN)\n",
        "\"\"\"\n",
        "# from fvcore.nn import FlopCountAnalysis\n",
        "# from fvcore.nn import flop_count_str\n",
        "# from fvcore.nn import flop_count_table"
      ],
      "metadata": {
        "id": "PKlMW3Nr_tKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "382504bc-bdf2-4e01-b68b-58a7974d65ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Unsafe for Colab (for Omni-SR, works fine with LESRCNN)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XS1LfMXrlodL"
      },
      "outputs": [],
      "source": [
        "# Local imports\n",
        "from utils.efficiency_results import get_model_flops, get_model_activation\n",
        "from lesrcnn.model import Net\n",
        "from omni.model import OmniSR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uHeOR7Be_pLV"
      },
      "outputs": [],
      "source": [
        "def cpu_inference(model, input):\n",
        "    \"\"\"\n",
        "        Little function for calculating inference time on CPU\n",
        "        Averages over 100 inferences\n",
        "    \"\"\"\n",
        "    start_time = perf_counter()\n",
        "    _ = model(input)\n",
        "    end_time = perf_counter()\n",
        "    delta = end_time - start_time\n",
        "\n",
        "    return delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SHYZ0yxsn5g1",
        "outputId": "fd9f0578-9165-41bd-8ee9-6e23c6ce8489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n",
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n",
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n",
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n",
            "window_size: 8\n",
            "with_pe True\n",
            "ffn_bias: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "# model = Net() # LESRCNN\n",
        "model = OmniSR() # Omni-SR network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3g63Be08_pLX"
      },
      "outputs": [],
      "source": [
        "deltas = []\n",
        "for _ in range(100):\n",
        "    input = torch.randn(1, 3, 256, 256)\n",
        "    deltas.append(cpu_inference(model, input))\n",
        "\n",
        "average_time = np.array(deltas).mean()\n",
        "print(\"inference time: {:.2f} ms\".format(average_time * 1e3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  GPU Inference time\n",
        "  https://pytorch.org/docs/stable/generated/torch.cuda.Event.html\n",
        "\"\"\"\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "input = torch.randn(1, 3, 256, 256, dtype=torch.float).to(device)"
      ],
      "metadata": {
        "id": "pId5nKQnAeIT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate logging\n",
        "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "iterations = 100\n",
        "deltas = np.zeros((iterations,1))\n",
        "\n",
        "# GPU warm-up\n",
        "with torch.no_grad():\n",
        "  for _ in range(10):\n",
        "      _ = model(input)\n",
        "\n",
        "# Average performance over 100 iterations\n",
        "with torch.no_grad():\n",
        "    for i in range(iterations):\n",
        "        starter.record()\n",
        "\n",
        "        _ = model(input)\n",
        "\n",
        "        ender.record()\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        delta = starter.elapsed_time(ender)\n",
        "        deltas[i] = delta\n",
        "\n",
        "average_time = np.sum(deltas) / iterations\n",
        "\n",
        "print(\"Average GPU inference time: {:.2f} ms\".format(average_time))"
      ],
      "metadata": {
        "id": "Giuzdt7iIuYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ-DBLqnn_Xm",
        "outputId": "79146607-ec29-46af-f24f-ce090cfac0c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    #Activations : 173.7359 [M]\n",
            "         #Conv2d : 26\n",
            "           FLOPs : 80.1813 [G]\n",
            "         #Params : 0.6263 [M]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "To find the number of activations.\n",
        "Model summary tools based on NTIRE challenge on efficient super-resolution: https://cvlai.net/ntire/2023/\n",
        "\"\"\"\n",
        "input_dim = (3, 256, 256)\n",
        "activations, num_conv = get_model_activation(model, input_dim)\n",
        "activations = activations / 10 ** 6\n",
        "print(\"{:>16s} : {:<.4f} [M]\".format(\"#Activations\", activations))\n",
        "print(\"{:>16s} : {:<d}\".format(\"#Conv2d\", num_conv))\n",
        "\n",
        "\n",
        "flops = get_model_flops(model, input_dim, False)\n",
        "flops = flops / 10 ** 9\n",
        "print(\"{:>16s} : {:<.4f} [G]\".format(\"FLOPs\", flops))\n",
        "\n",
        "num_parameters = sum(map(lambda x: x.numel(), model.parameters()))\n",
        "num_parameters = num_parameters / 10 ** 6\n",
        "print(\"{:>16s} : {:<.4f} [M]\".format(\"#Params\", num_parameters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugPCdvaTs8HQ",
        "outputId": "490650d5-e4cd-46b3-d2a5-8a0c5d642eaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsupported operator aten::add encountered 9 time(s)\n",
            "Unsupported operator aten::pixel_shuffle encountered 2 time(s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FLOPs: {.3f} [G] 80.026075136\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Alternative tool for calculating FLOPs: Fvcore by Facebook research\n",
        "https://github.com/facebookresearch/fvcore\n",
        "\"\"\"\n",
        "\n",
        "input = torch.randn(1, 3, 256, 256)\n",
        "flops = FlopCountAnalysis(model, input)\n",
        "print(\"FLOPs: {:.2f} [G]\".format(flops.total() / 1e9))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH_lQbUm_pLa",
        "outputId": "ca1cfe93-5df4-45ff-fa01-113e564d2ce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| module                      | #parameters or shape   | #flops   |\n",
            "|:----------------------------|:-----------------------|:---------|\n",
            "| model                       | 0.626M                 | 80.026G  |\n",
            "|  sub_mean.shifter           |  12                    |  0.59M   |\n",
            "|   sub_mean.shifter.weight   |   (3, 3, 1, 1)         |          |\n",
            "|   sub_mean.shifter.bias     |   (3,)                 |          |\n",
            "|  add_mean.shifter           |  12                    |  2.359M  |\n",
            "|   add_mean.shifter.weight   |   (3, 3, 1, 1)         |          |\n",
            "|   add_mean.shifter.bias     |   (3,)                 |          |\n",
            "|  conv1.0                    |  1.728K                |  0.113G  |\n",
            "|   conv1.0.weight            |   (64, 3, 3, 3)        |          |\n",
            "|  conv2.0                    |  36.864K               |  2.416G  |\n",
            "|   conv2.0.weight            |   (64, 64, 3, 3)       |          |\n",
            "|  conv3.0                    |  4.096K                |  0.268G  |\n",
            "|   conv3.0.weight            |   (64, 64, 1, 1)       |          |\n",
            "|  conv4.0                    |  36.864K               |  2.416G  |\n",
            "|   conv4.0.weight            |   (64, 64, 3, 3)       |          |\n",
            "|  conv5.0                    |  4.096K                |  0.268G  |\n",
            "|   conv5.0.weight            |   (64, 64, 1, 1)       |          |\n",
            "|  conv6.0                    |  36.864K               |  2.416G  |\n",
            "|   conv6.0.weight            |   (64, 64, 3, 3)       |          |\n",
            "|  conv7.0                    |  4.096K                |  0.268G  |\n",
            "|   conv7.0.weight            |   (64, 64, 1, 1)       |          |\n",
            "|  conv8.0                    |  36.864K               |  2.416G  |\n",
            "|   conv8.0.weight            |   (64, 64, 3, 3)       |          |\n",
            "|  conv9.0                    |  4.096K                |  0.268G  |\n",
            "|   conv9.0.weight            |   (64, 64, 1, 1)       |          |\n",
            "|  conv10.0                   |  36.864K               |  2.416G  |\n",
            "|   conv10.0.weight           |   (64, 64, 3, 3)       |          |\n",
            "|  conv11.0                   |  4.096K                |  0.268G  |\n",
            "|   conv11.0.weight           |   (64, 64, 1, 1)       |          |\n",
            "|  conv12.0                   |  36.864K               |  2.416G  |\n",
            "|   conv12.0.weight           |   (64, 64, 3, 3)       |          |\n",
            "|  conv13.0                   |  4.096K                |  0.268G  |\n",
            "|   conv13.0.weight           |   (64, 64, 1, 1)       |          |\n",
            "|  conv14.0                   |  36.864K               |  2.416G  |\n",
            "|   conv14.0.weight           |   (64, 64, 3, 3)       |          |\n",
            "|  conv15.0                   |  4.096K                |  0.268G  |\n",
            "|   conv15.0.weight           |   (64, 64, 1, 1)       |          |\n",
            "|  conv16.0                   |  36.864K               |  2.416G  |\n",
            "|   conv16.0.weight           |   (64, 64, 3, 3)       |          |\n",
            "|  conv17.0                   |  4.096K                |  0.268G  |\n",
            "|   conv17.0.weight           |   (64, 64, 1, 1)       |          |\n",
            "|  conv17_1.0                 |  36.864K               |  9.664G  |\n",
            "|   conv17_1.0.weight         |   (64, 64, 3, 3)       |          |\n",
            "|  conv17_2.0                 |  36.864K               |  9.664G  |\n",
            "|   conv17_2.0.weight         |   (64, 64, 3, 3)       |          |\n",
            "|  conv17_3.0                 |  36.864K               |  9.664G  |\n",
            "|   conv17_3.0.weight         |   (64, 64, 3, 3)       |          |\n",
            "|  conv17_4.0                 |  36.864K               |  9.664G  |\n",
            "|   conv17_4.0.weight         |   (64, 64, 3, 3)       |          |\n",
            "|  conv18.0                   |  1.728K                |  0.453G  |\n",
            "|   conv18.0.weight           |   (3, 64, 3, 3)        |          |\n",
            "|  upsample.up.body.0         |  0.148M                |  19.327G |\n",
            "|   upsample.up.body.0.weight |   (256, 64, 3, 3)      |          |\n",
            "|   upsample.up.body.0.bias   |   (256,)               |          |\n"
          ]
        }
      ],
      "source": [
        "# Layer-wise statistics\n",
        "print(flop_count_table(flops))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg7T7XTn_pLa",
        "outputId": "20bb6f80-5bed-47fc-cc58-7340fb8f5968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  #params: 0.63M, #flops: 80.03G\n",
            "  (sub_mean): MeanShift(\n",
            "    #params: 12, #flops: 0.59M\n",
            "    (shifter): Conv2d(\n",
            "      3, 3, kernel_size=(1, 1), stride=(1, 1)\n",
            "      #params: 12, #flops: 0.59M\n",
            "    )\n",
            "  )\n",
            "  (add_mean): MeanShift(\n",
            "    #params: 12, #flops: 2.36M\n",
            "    (shifter): Conv2d(\n",
            "      3, 3, kernel_size=(1, 1), stride=(1, 1)\n",
            "      #params: 12, #flops: 2.36M\n",
            "    )\n",
            "  )\n",
            "  (conv1): Sequential(\n",
            "    #params: 1.73K, #flops: 0.11G\n",
            "    (0): Conv2d(\n",
            "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 1.73K, #flops: 0.11G\n",
            "    )\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv6): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv7): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv8): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv9): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv10): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv11): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv12): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv13): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv14): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv15): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv16): Sequential(\n",
            "    #params: 36.86K, #flops: 2.42G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 2.42G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv17): Sequential(\n",
            "    #params: 4.1K, #flops: 0.27G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "      #params: 4.1K, #flops: 0.27G\n",
            "    )\n",
            "  )\n",
            "  (conv17_1): Sequential(\n",
            "    #params: 36.86K, #flops: 9.66G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 9.66G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv17_2): Sequential(\n",
            "    #params: 36.86K, #flops: 9.66G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 9.66G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv17_3): Sequential(\n",
            "    #params: 36.86K, #flops: 9.66G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 9.66G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv17_4): Sequential(\n",
            "    #params: 36.86K, #flops: 9.66G\n",
            "    (0): Conv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 36.86K, #flops: 9.66G\n",
            "    )\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (conv18): Sequential(\n",
            "    #params: 1.73K, #flops: 0.45G\n",
            "    (0): Conv2d(\n",
            "      64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      #params: 1.73K, #flops: 0.45G\n",
            "    )\n",
            "  )\n",
            "  (ReLU): ReLU(inplace=True)\n",
            "  (upsample): UpsampleBlock(\n",
            "    #params: 0.15M, #flops: 19.33G\n",
            "    (up): _UpsampleBlock(\n",
            "      #params: 0.15M, #flops: 19.33G\n",
            "      (body): Sequential(\n",
            "        #params: 0.15M, #flops: 19.33G\n",
            "        (0): Conv2d(\n",
            "          64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "          #params: 0.15M, #flops: 19.33G\n",
            "        )\n",
            "        (1): PixelShuffle(upscale_factor=2)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(flop_count_str(flops))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EymRByC_pLa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}